{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import re \n",
    "import numpy as np\n",
    "import Levenshtein as lev\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from modules.Deduplicator import Deduplicator\n",
    "from modules.DeduplicatorPolars import DeduplicatorPolars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRING_COLUMNS = ['title','artist','track01']\n",
    "\n",
    "# replace NaN with '' on STRING_COLUMNS\n",
    "def clean_strings(df):\n",
    "  df[STRING_COLUMNS] = df[STRING_COLUMNS].replace(np.nan, '')\n",
    "  return df\n",
    "\n",
    "# We don't remove non alphanumerics now, because we wouldn't be able to \n",
    "# undestand anything when we analyze the data. So we call this function \n",
    "# when we calculate the strings_distance\n",
    "def remove_non_alphanum(string: str):\n",
    "  return re.sub(r'\\W+', '', string)\n",
    "\n",
    "UNUSED_COLUMNS = ['id',\t\"category\",\"genre\",\"cdextra\",\"year\",\"track02\",\"track03\",\"track04\",\"track05\",\"track06\",\"track07\",\"track08\",\"track09\",\"track10\",\"track11\",\"track12\",\"track13\",\"track14\",\"track15\",\"track16\",\"track17\",\"track18\",\"track19\",\"track20\",\"track21\",\"track22\",\"track23\",\"track24\",\"track25\",\"track26\",\"track27\",\"track28\",\"track29\",\"track30\",\"track31\",\"track32\",\"track33\",\"track34\",\"track35\",\"track36\",\"track37\",\"track38\",\"track39\",\"track40\",\"track41\",\"track42\",\"track43\",\"track44\",\"track45\",\"track46\",\"track47\",\"track48\",\"track49\",\"track50\",\"track51\",\"track52\",\"track53\",\"track54\",\"track55\",\"track56\",\"track57\",\"track58\",\"track59\",\"track60\",\"track61\",\"track62\",\"track63\",\"track64\",\"track65\",\"track66\",\"track67\",\"track68\",\"track69\",\"track70\",\"track71\",\"track72\",\"track73\",\"track74\",\"track75\",\"track76\",\"track77\",\"track78\",\"track79\",\"track80\",\"track81\",\"track82\",\"track83\",\"track84\",\"track85\",\"track86\",\"track87\",\"track88\",\"track89\",\"track90\",\"track91\",\"track92\",\"track93\",\"track94\",\"track95\",\"track96\",\"track97\",\"track98\",\"track99\"]\n",
    "def remove_unused_columns(df):\n",
    "  return df.drop(columns = UNUSED_COLUMNS)\n",
    "\n",
    "# a single function that calls all the above clean functions\n",
    "def clean_db(df):\n",
    "  df = remove_unused_columns(df) # TODO : try not cleaning (much data in memory) to see how to improve operations\n",
    "  df = clean_strings(df)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_distance(string1: str, string2: str):\n",
    "  x = remove_non_alphanum(string1).lower()\n",
    "  y = remove_non_alphanum(string2).lower()\n",
    "  \n",
    "  dist = lev.distance(x, y) \n",
    "\n",
    "  max_len = max(len(x), len(y))\n",
    "  if (max_len == 0):\n",
    "    return 0\n",
    "  normalized = (max_len-dist) / max_len \n",
    "  normalized_dist = 1-normalized\n",
    "  return normalized_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_w = 1.2\n",
    "artist_w = 1\n",
    "track1_w = .8\n",
    "\n",
    "def distance(item: dict, item2: dict): \n",
    "  w_sum = 0\n",
    "\n",
    "  title_dist = 0\n",
    "  artist_dist = 0\n",
    "  track1_dist = 0\n",
    "  \n",
    "  if (item['title'] and item2['title']):\n",
    "    title_dist = string_distance(item['title'], item2['title'])\n",
    "    w_sum += title_w\n",
    "\n",
    "  if (item['artist'] and item2['artist']):\n",
    "    artist_dist = string_distance(item['artist'], item2['artist'])\n",
    "    w_sum += artist_w\n",
    "\n",
    "  if (item['track01'] and item2['track01']):\n",
    "    track1_dist = string_distance(item['track01'], item2['track01'])\n",
    "    w_sum += track1_w\n",
    "\n",
    "  dist = ( (title_dist*title_w) + (artist_dist*artist_w) ) + (track1_dist*track1_w) / w_sum\n",
    "  return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base toda 9763\n",
      "Base particao 1 6346\n",
      "Base particao 2 3417\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cd.csv', delimiter=';', doublequote=False)\n",
    "\n",
    "# evaluation\n",
    "gold_standard_df = pd.read_csv('cd_gold.csv', delimiter=';')\n",
    "gold_standard_pairs = gold_standard_df.values.tolist()\n",
    "\n",
    "# DATASET \n",
    "df = clean_db(df)\n",
    "\n",
    "second_partition_indices = df.sample(frac=0.35, random_state=42).index\n",
    "\n",
    "# Split the dataset into 2 incrementals\n",
    "df2 = df.loc[second_partition_indices]\n",
    "df1 = df.drop(second_partition_indices)\n",
    "\n",
    "print('Base toda', len(df))\n",
    "print('Base particao 1', len(df1))\n",
    "print('Base particao 2', len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~ EVALUATION ~~\n",
      "  Precision: 0.9459459459459459\n",
      "  Recall: 0.7023411371237458\n",
      "  F-measure: 0.8061420345489442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deduplicator = Deduplicator('title', distance, 'pk', 0.25)\n",
    "\n",
    "clusters = deduplicator.run(df)\n",
    "deduplicator.evaluate(gold_standard_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~ EVALUATION ~~\n",
      "  Precision: 0.9459459459459459\n",
      "  Recall: 0.7023411371237458\n",
      "  F-measure: 0.8061420345489442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deduplicator_pl = DeduplicatorPolars('title', distance, 'pk', 0.25)\n",
    "\n",
    "clusters_pl = deduplicator_pl.run(df)\n",
    "deduplicator_pl.evaluate(gold_standard_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~ EVALUATION ~~\n",
      "  Precision: 0.9591836734693877\n",
      "  Recall: 0.31438127090301005\n",
      "  F-measure: 0.473551637279597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deduplicator_inc = Deduplicator('title', distance, 'pk', 0.25)\n",
    "\n",
    "clusters_inc = deduplicator_inc.run(df1)\n",
    "deduplicator_inc.evaluate(gold_standard_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_inc = deduplicator_inc.run(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~ EVALUATION ~~\n",
      "  Precision: 0.9459459459459459\n",
      "  Recall: 0.7023411371237458\n",
      "  F-measure: 0.8061420345489442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deduplicator_inc.evaluate(gold_standard_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
